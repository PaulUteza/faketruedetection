{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:43:31.475729Z",
     "start_time": "2020-09-30T14:43:27.142646Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "#from wordcloud import WordCloud\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading fake and real news files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:43:32.927540Z",
     "start_time": "2020-09-30T14:43:31.479310Z"
    }
   },
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(r\"dataset/true.csv\")\n",
    "fake_df = pd.read_csv(r\"dataset/fake.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie Laurent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:43:32.940438Z",
     "start_time": "2020-09-30T14:43:32.929466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding class Information\n",
    "true_df[\"class\"] = 1\n",
    "fake_df[\"class\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there might be some empty text in those datasets (maybe the news is only made of a video ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:43:33.067660Z",
     "start_time": "2020-09-30T14:43:32.945425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21816</th>\n",
       "      <td>BALTIMORE BURNS: MARYLAND GOVERNOR BRINGS IN N...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 27, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21826</th>\n",
       "      <td>FULL VIDEO: THE BLOCKBUSTER INVESTIGATION INTO...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 25, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21827</th>\n",
       "      <td>(VIDEO) HILLARY CLINTON: RELIGIOUS BELIEFS MUS...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 25, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21857</th>\n",
       "      <td>(VIDEO)ICE PROTECTING OBAMA: WON’T RELEASE NAM...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 14, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21873</th>\n",
       "      <td>(VIDEO) HYSTERICAL SNL TAKE ON HILLARY’S ANNOU...</td>\n",
       "      <td></td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 12, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title text    subject  \\\n",
       "21816  BALTIMORE BURNS: MARYLAND GOVERNOR BRINGS IN N...       left-news   \n",
       "21826  FULL VIDEO: THE BLOCKBUSTER INVESTIGATION INTO...       left-news   \n",
       "21827  (VIDEO) HILLARY CLINTON: RELIGIOUS BELIEFS MUS...       left-news   \n",
       "21857  (VIDEO)ICE PROTECTING OBAMA: WON’T RELEASE NAM...       left-news   \n",
       "21873  (VIDEO) HYSTERICAL SNL TAKE ON HILLARY’S ANNOU...       left-news   \n",
       "\n",
       "               date  class  \n",
       "21816  Apr 27, 2015      0  \n",
       "21826  Apr 25, 2015      0  \n",
       "21827  Apr 25, 2015      0  \n",
       "21857  Apr 14, 2015      0  \n",
       "21873  Apr 12, 2015      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we are getting indexes of empty news \n",
    "empty_fake_index = [index for index,text in enumerate(fake_df.text.values) if str(text).strip() == '']\n",
    "\n",
    "#Checking some rows \n",
    "fake_df.iloc[empty_fake_index].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this and since it seems kinda pointless to separate them, we are merging the title and the text of the news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:43:33.415079Z",
     "start_time": "2020-09-30T14:43:33.071647Z"
    }
   },
   "outputs": [],
   "source": [
    "fake_df['text'] = fake_df['title'] + \" \" + fake_df['text']\n",
    "true_df['text'] = true_df['title'] + \" \" + true_df['text']\n",
    "\n",
    "fake_df = fake_df.drop(['title'], axis = 1)\n",
    "true_df = true_df.drop(['title'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We think the subject could have been an interesting addition but since they are different across both datasets they might cause an overfitting if the model is able to predict a fake news solely by having the subject be \"News\" for exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:43:33.430658Z",
     "start_time": "2020-09-30T14:43:33.416695Z"
    }
   },
   "outputs": [],
   "source": [
    "fake_df = fake_df.drop(['subject'], axis = 1)\n",
    "true_df = true_df.drop(['subject'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There might be some duplicated news so we are dropping them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:43:33.996718Z",
     "start_time": "2020-09-30T14:43:33.440630Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_df = true_df.drop_duplicates(keep=False)\n",
    "fake_df = fake_df.drop_duplicates(keep=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:43:34.016609Z",
     "start_time": "2020-09-30T14:43:33.999653Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33793</th>\n",
       "      <td>UPDATE: 40% OF VICTIM’S SKULL IS MISSING…No Ne...</td>\n",
       "      <td>Apr 11, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33794</th>\n",
       "      <td>‘MOTHER OF THE YEAR’ Drives11 And Armed 15 Yr....</td>\n",
       "      <td>Apr 10, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33795</th>\n",
       "      <td>IT’S TIME TO STOP THE LIES! ARE YOU SICK AND T...</td>\n",
       "      <td>Apr 9, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33796</th>\n",
       "      <td>[Video] BURGER KING MANAGER CURSES OUT AND THR...</td>\n",
       "      <td>Apr 7, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33797</th>\n",
       "      <td>SHOCKING: UNIV OF HAWAII RECRUITS GIRLS AS YOU...</td>\n",
       "      <td>Apr 7, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33798</th>\n",
       "      <td>BREAKING: [Video] COLORADO BAKER WHO REFUSED T...</td>\n",
       "      <td>Apr 7, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33799</th>\n",
       "      <td>(VIDEO) PATRIOTS DEMAND REMOVAL OF COMMUNIST F...</td>\n",
       "      <td>Apr 6, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33800</th>\n",
       "      <td>BUSTED: [VIDEO] MAN ATTEMPTS TO TAPE “GOTCHA” ...</td>\n",
       "      <td>Apr 5, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33801</th>\n",
       "      <td>[VIDEO] 16 YR OLD ARRESTED For Violent Gang Be...</td>\n",
       "      <td>Apr 4, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33802</th>\n",
       "      <td>“Non-violence hasn’t worked”…Reverend Sam Most...</td>\n",
       "      <td>Apr 1, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33803</th>\n",
       "      <td>The White House and The Theatrics of ‘Gun Cont...</td>\n",
       "      <td>January 7, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33804</th>\n",
       "      <td>Activists or Terrorists? How Media Controls an...</td>\n",
       "      <td>January 7, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33805</th>\n",
       "      <td>BOILER ROOM – No Surrender, No Retreat, Heads ...</td>\n",
       "      <td>January 6, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33806</th>\n",
       "      <td>Federal Showdown Looms in Oregon After BLM Abu...</td>\n",
       "      <td>January 4, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33807</th>\n",
       "      <td>A Troubled King: Chicago’s Rahm Emanuel Desper...</td>\n",
       "      <td>January 2, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text             date  \\\n",
       "33793  UPDATE: 40% OF VICTIM’S SKULL IS MISSING…No Ne...     Apr 11, 2015   \n",
       "33794  ‘MOTHER OF THE YEAR’ Drives11 And Armed 15 Yr....     Apr 10, 2015   \n",
       "33795  IT’S TIME TO STOP THE LIES! ARE YOU SICK AND T...      Apr 9, 2015   \n",
       "33796  [Video] BURGER KING MANAGER CURSES OUT AND THR...      Apr 7, 2015   \n",
       "33797  SHOCKING: UNIV OF HAWAII RECRUITS GIRLS AS YOU...      Apr 7, 2015   \n",
       "33798  BREAKING: [Video] COLORADO BAKER WHO REFUSED T...      Apr 7, 2015   \n",
       "33799  (VIDEO) PATRIOTS DEMAND REMOVAL OF COMMUNIST F...      Apr 6, 2015   \n",
       "33800  BUSTED: [VIDEO] MAN ATTEMPTS TO TAPE “GOTCHA” ...      Apr 5, 2015   \n",
       "33801  [VIDEO] 16 YR OLD ARRESTED For Violent Gang Be...      Apr 4, 2015   \n",
       "33802  “Non-violence hasn’t worked”…Reverend Sam Most...      Apr 1, 2015   \n",
       "33803  The White House and The Theatrics of ‘Gun Cont...  January 7, 2016   \n",
       "33804  Activists or Terrorists? How Media Controls an...  January 7, 2016   \n",
       "33805  BOILER ROOM – No Surrender, No Retreat, Heads ...  January 6, 2016   \n",
       "33806  Federal Showdown Looms in Oregon After BLM Abu...  January 4, 2016   \n",
       "33807  A Troubled King: Chicago’s Rahm Emanuel Desper...  January 2, 2016   \n",
       "\n",
       "       class  \n",
       "33793      0  \n",
       "33794      0  \n",
       "33795      0  \n",
       "33796      0  \n",
       "33797      0  \n",
       "33798      0  \n",
       "33799      0  \n",
       "33800      0  \n",
       "33801      0  \n",
       "33802      0  \n",
       "33803      0  \n",
       "33804      0  \n",
       "33805      0  \n",
       "33806      0  \n",
       "33807      0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([true_df, fake_df], ignore_index=True, sort=False)\n",
    "\n",
    "data.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing text\n",
    "   ## First preprocessing\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:43:34.250149Z",
     "start_time": "2020-09-30T14:43:34.023589Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]','',text) # remove punctuation\n",
    "    text = re.sub('(\\s+)', ' ', text) # removing extra whitespaces\n",
    "    text = re.sub('\\[.*?\\]', '', text) # remove square brackets\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # remove words containing numbers\n",
    "    text = re.sub(r'http\\S+', '', text) # remove http\n",
    "    text = re.sub('\\n', '', text) # remove new lines\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 27,
=======
   "execution_count": 10,
>>>>>>> Stashed changes
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:52:24.335914Z",
     "start_time": "2020-09-30T14:52:02.486149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33803</th>\n",
       "      <td>the white house and the theatrics of gun contr...</td>\n",
       "      <td>January 7, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33804</th>\n",
       "      <td>activists or terrorists how media controls and...</td>\n",
       "      <td>January 7, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33805</th>\n",
       "      <td>boiler room no surrender no retreat heads will...</td>\n",
       "      <td>January 6, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33806</th>\n",
       "      <td>federal showdown looms in oregon after blm abu...</td>\n",
       "      <td>January 4, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33807</th>\n",
       "      <td>a troubled king chicagos rahm emanuel desperat...</td>\n",
       "      <td>January 2, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text             date  \\\n",
       "33803  the white house and the theatrics of gun contr...  January 7, 2016   \n",
       "33804  activists or terrorists how media controls and...  January 7, 2016   \n",
       "33805  boiler room no surrender no retreat heads will...  January 6, 2016   \n",
       "33806  federal showdown looms in oregon after blm abu...  January 4, 2016   \n",
       "33807  a troubled king chicagos rahm emanuel desperat...  January 2, 2016   \n",
       "\n",
       "       class  \n",
       "33803      0  \n",
       "33804      0  \n",
       "33805      0  \n",
       "33806      0  \n",
       "33807      0  "
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 27,
=======
     "execution_count": 10,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_data_1 = data.copy()\n",
    "preprocessing_data_1['text'] = preprocessing_data_1.text.apply(lambda text : first_preprocessing(text))\n",
    "preprocessing_data_1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 28,
=======
   "execution_count": 11,
>>>>>>> Stashed changes
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:51:54.372037Z",
     "start_time": "2020-09-30T14:51:54.366053Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_sentence = []\n",
    "    for w in tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "\n",
    "    return \" \".join(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 29,
=======
   "execution_count": 12,
>>>>>>> Stashed changes
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T14:53:35.434304Z",
     "start_time": "2020-09-30T14:52:24.745818Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33803</th>\n",
       "      <td>white house theatrics gun control century wire...</td>\n",
       "      <td>January 7, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33804</th>\n",
       "      <td>activists terrorists media controls dictates n...</td>\n",
       "      <td>January 7, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33805</th>\n",
       "      <td>boiler room surrender retreat heads roll ep tu...</td>\n",
       "      <td>January 6, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33806</th>\n",
       "      <td>federal showdown looms oregon blm abuse local ...</td>\n",
       "      <td>January 4, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33807</th>\n",
       "      <td>troubled king chicagos rahm emanuel desperate ...</td>\n",
       "      <td>January 2, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text             date  \\\n",
       "33803  white house theatrics gun control century wire...  January 7, 2016   \n",
       "33804  activists terrorists media controls dictates n...  January 7, 2016   \n",
       "33805  boiler room surrender retreat heads roll ep tu...  January 6, 2016   \n",
       "33806  federal showdown looms oregon blm abuse local ...  January 4, 2016   \n",
       "33807  troubled king chicagos rahm emanuel desperate ...  January 2, 2016   \n",
       "\n",
       "       class  \n",
       "33803      0  \n",
       "33804      0  \n",
       "33805      0  \n",
       "33806      0  \n",
       "33807      0  "
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 29,
=======
     "execution_count": 12,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_data_1['text'] = preprocessing_data_1.text.apply(lambda text : remove_stopwords(text))\n",
    "preprocessing_data_1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 30,
=======
   "execution_count": 13,
>>>>>>> Stashed changes
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T15:00:30.383297Z",
     "start_time": "2020-09-30T15:00:30.376315Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    text = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 31,
=======
   "execution_count": 14,
>>>>>>> Stashed changes
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T15:01:47.806008Z",
     "start_time": "2020-09-30T15:00:32.695724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33803</th>\n",
       "      <td>white house theatrics gun control century wire...</td>\n",
       "      <td>January 7, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33804</th>\n",
       "      <td>activist terrorist medium control dictate narr...</td>\n",
       "      <td>January 7, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33805</th>\n",
       "      <td>boiler room surrender retreat head roll ep tun...</td>\n",
       "      <td>January 6, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33806</th>\n",
       "      <td>federal showdown loom oregon blm abuse local r...</td>\n",
       "      <td>January 4, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33807</th>\n",
       "      <td>troubled king chicago rahm emanuel desperate s...</td>\n",
       "      <td>January 2, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text             date  \\\n",
       "33803  white house theatrics gun control century wire...  January 7, 2016   \n",
       "33804  activist terrorist medium control dictate narr...  January 7, 2016   \n",
       "33805  boiler room surrender retreat head roll ep tun...  January 6, 2016   \n",
       "33806  federal showdown loom oregon blm abuse local r...  January 4, 2016   \n",
       "33807  troubled king chicago rahm emanuel desperate s...  January 2, 2016   \n",
       "\n",
       "       class  \n",
       "33803      0  \n",
       "33804      0  \n",
       "33805      0  \n",
       "33806      0  \n",
       "33807      0  "
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 31,
=======
     "execution_count": 14,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_data_1['text'] = preprocessing_data_1.text.apply(lambda text : lemmatization(text))\n",
    "preprocessing_data_1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie Marcel"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-5fff1bdee021>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mcount_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mvalue_data1_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_data1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#on a besoin d'une représentation numérique des mots afin de nourrir notre algo knn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m             \u001b[0mj_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m             \u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [27046, 6762]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5fff1bdee021>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#clf = knn.fit(value_data1_train_tfidf_train,label_data1_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_data1_train_tfidf_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue_data1_train_tfidf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#prédiction du modèle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \"\"\"\n\u001b[0;32m   1130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m             X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n\u001b[0m\u001b[0;32m   1132\u001b[0m                                        multi_output=True)\n\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 813\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [27046, 6762]"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#label_data1 contient les label donc les 0 et 1 dans notre cas\n",
    "value_data1 = preprocessing_data_1.iloc[:,0:2].values\n",
    "label_data1 = preprocessing_data_1.iloc[:,-1].values\n",
    "\n",
    "value_data1.T[0]\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "value_data1_counts = count_vect.fit_transform(value_data1.T[0])\n",
    "\n",
    "#on a besoin d'une représentation numérique des mots afin de nourrir notre algo knn\n",
    "#on va donc faire la méthode de pondération tf-idf\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "value_data1_train_tfidf = tfidf_transformer.fit_transform(value_data1_counts)\n",
    "\n",
    "#séparons le dataset en train et test\n",
    "value_data1_train_tfidf_train, value_data1_train_tfidf_test, label_data1_train, label_data1_test = train_test_split(value_data1_train_tfidf, label_data1, test_size=0.20)\n",
    "\n",
    "#mis en place du fit\n",
    "\n",
    "#entrainement du modèle\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "#clf = knn.fit(value_data1_train_tfidf_train,label_data1_train)\n",
    "clf = knn.fit(value_data1_train_tfidf_train,value_data1_train_tfidf_test)\n",
    "\n",
    "#prédiction du modèle\n",
    "X_new_counts = count_vect.transform(value_data1_train_tfidf_test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "pred = classifier.predict(X_new_tfidf)\n",
    "\n",
    "\n",
    "# transform a count matrix to a normalized tf-idf representation (tf-idf transformer)\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#value_data1_counts_fidf = tfidf_transformer.fit_transform()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "219.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "1249.2px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
